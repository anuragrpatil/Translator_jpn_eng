{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ENG-JPN.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"jGCXx3MGURws","colab_type":"code","colab":{}},"cell_type":"code","source":["#english to japanese SEQ2SEQ model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kC9zcMyWUTQb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8072398e-43f2-4b1c-bfce-70285388bda8","executionInfo":{"status":"ok","timestamp":1555941994341,"user_tz":-330,"elapsed":1139,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"CdV5Zs07US9-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"ee19afb0-b7ef-40a9-dcb2-7d0c032ef2b4","executionInfo":{"status":"ok","timestamp":1555942794657,"user_tz":-330,"elapsed":5656,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["!pwd\n","%cd ./gdrive/My Drive/Projects/Colab Notebooks/Keras-SEQ2SEQ-NMT-english-Japanese-master"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n","/content/gdrive/My Drive/Projects/Colab Notebooks/Keras-SEQ2SEQ-NMT-english-Japanese-master\n"],"name":"stdout"}]},{"metadata":{"id":"zVavStKmURwy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"de725ebb-bb50-499c-a9cb-a18e78a12b40","executionInfo":{"status":"ok","timestamp":1555942797791,"user_tz":-330,"elapsed":8555,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["from keras.models import Model\n","from keras.layers.recurrent import LSTM\n","from keras.layers import Dense, Input, Embedding\n","from keras.preprocessing.sequence import pad_sequences\n","from collections import Counter\n","from keras.callbacks import ModelCheckpoint\n","import nltk\n","import numpy as np\n","import os\n","import zipfile\n","import sys\n","import urllib.request\n","from gensim.models import KeyedVectors\n","from keras.utils import plot_model\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"6t9CsiJtURw3","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.activations import softmax\n","from keras.layers.core import Dense, Activation, RepeatVector, Permute\n","from keras.layers import Input, Embedding, Multiply, Concatenate, Lambda\n","from keras.layers.wrappers import TimeDistributed"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uIinGP80URw5","colab_type":"text"},"cell_type":"markdown","source":["#hyperparameters"]},{"metadata":{"id":"TzBKtKj2URw6","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 64\n","NUM_EPOCHS = 100\n","HIDDEN_UNITS = 256\n","NUM_SAMPLES = 10000\n","MAX_VOCAB_SIZE = 2000\n","EMBEDDING_SIZE = 100\n","DATA = 'jpn.txt'#loading data from default work directory"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K3mDTsAWURw9","colab_type":"code","colab":{}},"cell_type":"code","source":["tar_count = Counter()\n","\n","GLOVE_MODEL = \"glove.6B.100d.txt\"\n","WEIGHT_FILE_PATH = 'eng-to-jpn-glove-weights.h5'\n","MODEL_FILE_PATH = 'eng-to-jpn-glove-model.h5'\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"trj_YxaXURxA","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_glove():\n","    \n","    _word2em = {}\n","    file = open(GLOVE_MODEL, mode='r', encoding='utf8')\n","    for line in file:\n","        words = line.strip().split()\n","        word = words[0]\n","        embeds = np.array(words[1:], dtype=np.float32)\n","        _word2em[word] = embeds\n","    file.close()\n","    return _word2em"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JU_fqR8ZURxD","colab_type":"code","colab":{}},"cell_type":"code","source":["word2em = load_glove()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mq-zgx2RURxF","colab_type":"code","colab":{}},"cell_type":"code","source":["lines = open(DATA, 'r', encoding='utf8').read().split('\\n')\n","for line in lines[: len(lines)-1]:\n","    input_text, target_text = line.split('\\t')\n","    input_words = [w for w in nltk.word_tokenize(input_text.lower())]\n","    target_text = '\\t' + target_text + '\\n'\n","    for char in target_text:\n","        tar_count[char] += 1\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hQrOQHhwURxJ","colab_type":"code","colab":{}},"cell_type":"code","source":["target_word2idx = dict()\n","\n","for idx, word in enumerate(tar_count.most_common(MAX_VOCAB_SIZE)):\n","    #print(word)\n","    target_word2idx[word[0]] = idx\n","\n","target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n","\n","num_decoder_tokens = len(target_idx2word)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T2pdCgjiURxN","colab_type":"code","colab":{}},"cell_type":"code","source":["unknown_emb = np.random.randn(EMBEDDING_SIZE)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6N3BX-csURxP","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder_max_seq_length = 0\n","decoder_max_seq_length = 0\n","\n","input_texts_word2em = []\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mc7ZaHx-URxT","colab_type":"code","colab":{}},"cell_type":"code","source":["#encoder word2index input"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U7C1BdopURxV","colab_type":"code","colab":{}},"cell_type":"code","source":["lines = open(DATA, 'r', encoding='utf8').read().split('\\n')\n","for line in lines[: min(NUM_SAMPLES, len(lines)-1)]:\n","    input_text, target_text = line.split('\\t')\n","    target_text = '\\t' + target_text + '\\n'\n","    input_words = [w for w in nltk.word_tokenize(input_text.lower())]\n","    encoder_input_wids = []\n","    for w in input_words:\n","        em = unknown_emb\n","        if w in word2em:\n","            em = word2em[w]\n","        encoder_input_wids.append(em)\n","    input_texts_word2em.append(encoder_input_wids)\n","    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n","    decoder_max_seq_length = max(len(target_text), decoder_max_seq_length)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aWT7zoUrURxX","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder_input_data = pad_sequences(input_texts_word2em, encoder_max_seq_length)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j5SJcLoHURxZ","colab_type":"code","colab":{}},"cell_type":"code","source":["#decoder word2index input"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vG7oo8MVURxc","colab_type":"code","colab":{}},"cell_type":"code","source":["decoder_target_data = np.zeros(shape=(NUM_SAMPLES, decoder_max_seq_length, num_decoder_tokens))\n","decoder_input_data = np.zeros(shape=(NUM_SAMPLES, decoder_max_seq_length, num_decoder_tokens))\n","lines = open(DATA, 'rt', encoding='utf8').read().split('\\n')\n","for lineIdx, line in enumerate(lines[: min(NUM_SAMPLES, len(lines)-1)]):\n","    _, target = line.split('\\t')\n","    target = '\\t' + target + '\\n'\n","    for idx, char in enumerate(target):\n","        if char in target_word2idx:\n","            w2idx = target_word2idx[char]\n","            decoder_input_data[lineIdx, idx, w2idx] = 1\n","            if idx > 0:\n","                decoder_target_data[lineIdx, idx-1, w2idx] = 1\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_0dEKVh-URxe","colab_type":"code","colab":{}},"cell_type":"code","source":["context = dict()\n","context['num_decoder_tokens'] = num_decoder_tokens\n","context['encoder_max_seq_length'] = encoder_max_seq_length\n","context['decoder_max_seq_length'] = decoder_max_seq_length\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"37yZAL3tURxg","colab_type":"code","colab":{}},"cell_type":"code","source":["#defining Encoder- Decoder Model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xbgsGWyuURxk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"bbd33fcd-9197-40a6-c3b0-0c95b7d8564b","executionInfo":{"status":"ok","timestamp":1555942822417,"user_tz":-330,"elapsed":22292,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["encoder_inputs = Input(shape=(None, EMBEDDING_SIZE), name='encoder_inputs')\n","encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n","encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n","encoder_states = [encoder_state_h, encoder_state_c]\n","\n","decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_inputs')\n","decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n","decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n","                                                                 initial_state=encoder_states)\n","decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"id":"U07xf6TsURxn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3590},"outputId":"46d88d9c-6d9a-48e6-85aa-317ae3042d0f","executionInfo":{"status":"ok","timestamp":1555944505893,"user_tz":-330,"elapsed":1637634,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","\n","\n","checkpoint = ModelCheckpoint(filepath=WEIGHT_FILE_PATH, save_best_only=True)\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n","          verbose=1, validation_split=0.3, callbacks=[checkpoint])\n","\n","model.save_weights(WEIGHT_FILE_PATH)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Train on 7000 samples, validate on 3000 samples\n","Epoch 1/100\n","7000/7000 [==============================] - 21s 3ms/step - loss: 1.5155 - val_loss: 1.7014\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'encoder_lstm/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 1.3416 - val_loss: 1.6419\n","Epoch 3/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 1.2775 - val_loss: 1.5742\n","Epoch 4/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 1.1970 - val_loss: 1.4764\n","Epoch 5/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 1.1121 - val_loss: 1.3913\n","Epoch 6/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 1.0392 - val_loss: 1.3296\n","Epoch 7/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.9816 - val_loss: 1.2742\n","Epoch 8/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.9311 - val_loss: 1.2340\n","Epoch 9/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.8875 - val_loss: 1.1988\n","Epoch 10/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.8472 - val_loss: 1.1684\n","Epoch 11/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.8104 - val_loss: 1.1431\n","Epoch 12/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.7757 - val_loss: 1.1221\n","Epoch 13/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.7438 - val_loss: 1.0995\n","Epoch 14/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.7126 - val_loss: 1.0831\n","Epoch 15/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.6836 - val_loss: 1.0644\n","Epoch 16/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.6554 - val_loss: 1.0515\n","Epoch 17/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.6290 - val_loss: 1.0428\n","Epoch 18/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.6038 - val_loss: 1.0302\n","Epoch 19/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.5782 - val_loss: 1.0220\n","Epoch 20/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.5537 - val_loss: 1.0103\n","Epoch 21/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.5303 - val_loss: 1.0031\n","Epoch 22/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.5072 - val_loss: 1.0005\n","Epoch 23/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.4847 - val_loss: 0.9954\n","Epoch 24/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.4640 - val_loss: 0.9950\n","Epoch 25/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.4423 - val_loss: 1.0001\n","Epoch 26/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.4228 - val_loss: 0.9931\n","Epoch 27/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.4030 - val_loss: 0.9978\n","Epoch 28/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.3851 - val_loss: 0.9999\n","Epoch 29/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.3663 - val_loss: 0.9987\n","Epoch 30/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.3491 - val_loss: 1.0039\n","Epoch 31/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.3316 - val_loss: 1.0048\n","Epoch 32/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.3150 - val_loss: 1.0130\n","Epoch 33/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.2995 - val_loss: 1.0199\n","Epoch 34/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.2850 - val_loss: 1.0180\n","Epoch 35/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.2700 - val_loss: 1.0288\n","Epoch 36/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.2560 - val_loss: 1.0348\n","Epoch 37/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.2417 - val_loss: 1.0471\n","Epoch 38/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.2296 - val_loss: 1.0517\n","Epoch 39/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.2172 - val_loss: 1.0679\n","Epoch 40/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.2066 - val_loss: 1.0752\n","Epoch 41/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1951 - val_loss: 1.0863\n","Epoch 42/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1854 - val_loss: 1.1008\n","Epoch 43/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1758 - val_loss: 1.1010\n","Epoch 44/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1664 - val_loss: 1.1157\n","Epoch 45/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.1566 - val_loss: 1.1207\n","Epoch 46/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1476 - val_loss: 1.1336\n","Epoch 47/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1400 - val_loss: 1.1484\n","Epoch 48/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1322 - val_loss: 1.1523\n","Epoch 49/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1251 - val_loss: 1.1669\n","Epoch 50/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1200 - val_loss: 1.1718\n","Epoch 51/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1121 - val_loss: 1.1816\n","Epoch 52/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1071 - val_loss: 1.1959\n","Epoch 53/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.1011 - val_loss: 1.2114\n","Epoch 54/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0965 - val_loss: 1.2230\n","Epoch 55/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0917 - val_loss: 1.2245\n","Epoch 56/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0865 - val_loss: 1.2310\n","Epoch 57/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0814 - val_loss: 1.2464\n","Epoch 58/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0793 - val_loss: 1.2554\n","Epoch 59/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0754 - val_loss: 1.2637\n","Epoch 60/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0709 - val_loss: 1.2698\n","Epoch 61/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0680 - val_loss: 1.2858\n","Epoch 62/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0651 - val_loss: 1.2907\n","Epoch 63/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0626 - val_loss: 1.3030\n","Epoch 64/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0603 - val_loss: 1.3119\n","Epoch 65/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0588 - val_loss: 1.3205\n","Epoch 66/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0569 - val_loss: 1.3284\n","Epoch 67/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0551 - val_loss: 1.3278\n","Epoch 68/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0532 - val_loss: 1.3402\n","Epoch 69/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0510 - val_loss: 1.3482\n","Epoch 70/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0505 - val_loss: 1.3541\n","Epoch 71/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0483 - val_loss: 1.3592\n","Epoch 72/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0468 - val_loss: 1.3670\n","Epoch 73/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0455 - val_loss: 1.3701\n","Epoch 74/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0452 - val_loss: 1.3799\n","Epoch 75/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0439 - val_loss: 1.3944\n","Epoch 76/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0435 - val_loss: 1.3993\n","Epoch 77/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0415 - val_loss: 1.3980\n","Epoch 78/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0406 - val_loss: 1.4051\n","Epoch 79/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0397 - val_loss: 1.4172\n","Epoch 80/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0390 - val_loss: 1.4143\n","Epoch 81/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0381 - val_loss: 1.4134\n","Epoch 82/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0372 - val_loss: 1.4302\n","Epoch 83/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0364 - val_loss: 1.4236\n","Epoch 84/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0359 - val_loss: 1.4346\n","Epoch 85/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0354 - val_loss: 1.4364\n","Epoch 86/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0348 - val_loss: 1.4467\n","Epoch 87/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0352 - val_loss: 1.4401\n","Epoch 88/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0342 - val_loss: 1.4396\n","Epoch 89/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0343 - val_loss: 1.4544\n","Epoch 90/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0339 - val_loss: 1.4571\n","Epoch 91/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0332 - val_loss: 1.4657\n","Epoch 92/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0341 - val_loss: 1.4650\n","Epoch 93/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0325 - val_loss: 1.4562\n","Epoch 94/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0319 - val_loss: 1.4687\n","Epoch 95/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0317 - val_loss: 1.4790\n","Epoch 96/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0311 - val_loss: 1.4688\n","Epoch 97/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0318 - val_loss: 1.4851\n","Epoch 98/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0318 - val_loss: 1.4807\n","Epoch 99/100\n","7000/7000 [==============================] - 16s 2ms/step - loss: 0.0330 - val_loss: 1.4809\n","Epoch 100/100\n","7000/7000 [==============================] - 17s 2ms/step - loss: 0.0311 - val_loss: 1.4760\n"],"name":"stdout"}]},{"metadata":{"id":"Yn_PFozgURx3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"outputId":"098d5116-dfb4-4769-ac93-b3a302d65502","executionInfo":{"status":"ok","timestamp":1555947605586,"user_tz":-330,"elapsed":1646,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["model.summary()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoder_inputs (InputLayer)     (None, None, 100)    0                                            \n","__________________________________________________________________________________________________\n","decoder_inputs (InputLayer)     (None, None, 2000)   0                                            \n","__________________________________________________________________________________________________\n","encoder_lstm (LSTM)             [(None, 256), (None, 365568      encoder_inputs[0][0]             \n","__________________________________________________________________________________________________\n","decoder_lstm (LSTM)             [(None, None, 256),  2311168     decoder_inputs[0][0]             \n","                                                                 encoder_lstm[0][1]               \n","                                                                 encoder_lstm[0][2]               \n","__________________________________________________________________________________________________\n","decoder_dense (Dense)           (None, None, 2000)   514000      decoder_lstm[0][0]               \n","==================================================================================================\n","Total params: 3,190,736\n","Trainable params: 3,190,736\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"W4_IeUbiURx5","colab_type":"code","colab":{}},"cell_type":"code","source":["#Model to Test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"egbSfCOrURx7","colab_type":"code","colab":{}},"cell_type":"code","source":["# Encoder inference model\n","encoder_model_inf = Model(encoder_inputs, encoder_states)\n","\n","# Decoder inference model\n","\n","decoder_state_input_h = Input(shape=(HIDDEN_UNITS,))\n","decoder_state_input_c = Input(shape=(HIDDEN_UNITS,))\n","decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_out, decoder_h, decoder_c = decoder_lstm(decoder_inputs, \n","                                                 initial_state=decoder_input_states)\n","\n","decoder_states = [decoder_h , decoder_c]\n","\n","decoder_out = decoder_dense(decoder_out)\n","\n","decoder_model_inf = Model(inputs=[decoder_inputs] + decoder_input_states,\n","                          outputs=[decoder_out] + decoder_states )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yFTbeY5xURx-","colab_type":"code","colab":{}},"cell_type":"code","source":["max_encoder_seq_length = context['encoder_max_seq_length']\n","max_decoder_seq_length = context['decoder_max_seq_length']\n","num_decoder_tokens = context['num_decoder_tokens']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7QcqT62EURyB","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict_sent(input_text):\n","        input_seq = []\n","        input_wids = []\n","        for word in nltk.word_tokenize(input_text.lower()):\n","            emb = unknown_emb\n","            if word in word2em:\n","                emb = word2em[word]\n","            input_wids.append(emb)\n","        input_seq.append(input_wids)\n","        input_seq = pad_sequences(input_seq, max_encoder_seq_length)\n","        states_value = encoder_model_inf.predict(input_seq)\n","        target_seq = np.zeros((1, 1,num_decoder_tokens))\n","        target_seq[0, 0, target_word2idx['\\t']] = 1\n","        target_text = ''\n","        terminated = False\n","        while not terminated:\n","            output_tokens, h, c = decoder_model_inf.predict([target_seq] + states_value)\n","\n","            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n","            sample_word = target_idx2word[sample_token_idx]\n","            target_text += sample_word\n","\n","            if sample_word == '\\n' or len(target_text) >= max_decoder_seq_length:\n","                terminated = True\n","\n","            target_seq = np.zeros((1, 1, num_decoder_tokens))\n","            target_seq[0, 0, sample_token_idx] = 1\n","\n","            states_value = [h, c]\n","        return target_text.strip()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1mj_jiwpURyD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"350d9552-d134-4744-9d7e-b9cca9bd6505","executionInfo":{"status":"ok","timestamp":1555947763254,"user_tz":-330,"elapsed":1468,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["print(predict_sent('He is sick.'))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["彼は病気です。\n"],"name":"stdout"}]},{"metadata":{"id":"IeeIGf38URyH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":300},"outputId":"f8e40346-5822-4661-b948-d656afdebde4","executionInfo":{"status":"error","timestamp":1555947665778,"user_tz":-330,"elapsed":1979,"user":{"displayName":"PATIL ANURAG RAJEEV","photoUrl":"https://lh4.googleusercontent.com/-foYYdgGspjI/AAAAAAAAAAI/AAAAAAAAAA0/wM7W_TmM7XU/s64/photo.jpg","userId":"18183198384968558834"}}},"cell_type":"code","source":["# download model image file\n","from google.colab import files\n","files.download(MODEL_FILE_PATH)"],"execution_count":29,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-daba034244d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_FILE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0mstarted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_threading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: eng-to-jpn-glove-model.h5"]}]},{"metadata":{"id":"4m5n2MgFtTF0","colab_type":"code","colab":{}},"cell_type":"code","source":["# download model image file\n","from google.colab import files\n","files.download(WEIGHT_FILE_PATH)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BEt1Mm2VtcLB","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}